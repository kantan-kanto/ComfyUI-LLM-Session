# ComfyUI-LLM-Session Requirements

# Core dependencies
llama-cpp-python>=0.3.16  # 0.3.21+ recommended for Qwen3-VL support
pillow>=10.0.0
numpy>=1.24.0

# Optional: For better performance
# llama-cpp-python==0.3.21  # JamePeng fork for Qwen3-VL vision support

# Note: ComfyUI and its dependencies (torch, etc.) are assumed to be installed
